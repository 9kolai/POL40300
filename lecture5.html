<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>POL40300: Lecture5</title>

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css">
		<link rel="stylesheet" href="css/reveal-override.css"/>

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<header><img src="pic/LogoMainBlue2.png" style="width:100% "></header>
		<div class="reveal">
			<div class="slides">
				<section data-background="pic/BGMainBlue.gif" style="color:white">
					<h1  style="color:white">POL40300: Computational Methods</h1>
					<p>Lecture 5 by Nikolai Gad</p>
					<p>München, 13. November 2019</p>
				</section>
				<section>
					<h3 style="color: rgb(0,101,189)">Today's lecture </h3>
					<ul>
						<li>Practicals  </li>
						<li>Introduction to automated text analysis </li>
						<li>An example of automated text analysis in PolSci</li>
						<li>Introduction to text analysis in R (Quanteda) </li>
						
					</ul>
				</section>



				<section>
					<h1>Introduction to automated text analysis </h1>
					<p class="fragment">Grimmer, J., & Stewart, B. M. (2013). Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts. Political Analysis, 21(3), 267–297.</p>
				</section>
				
				
				<section>
					<h3 style="color: rgb(0,101,189)">Steps in automated text analysis. </h3>
					<ol>
						<li class="fragment">Collect text data (we will cover this later). </li>
						<li class="fragment">Pre-processing data (quantifying text). </li>
						<li class="fragment">Analysing text data. </li>
					</ol>
				</section>
				<section>
					<h3 style="color: rgb(0,101,189)">Pre-processing text data. </h3>
					<section>
						<p>Goal is to quantify text so we can do calculations on it. </p>
						<p class="fragment">This necessarily involves <em>reducing complexity</em>. </p>
					</section>
					<section>
						<h2>Some terminology: </h2>
						<ul>
							<li class="fragment">Document/text: Usually the unit of analysis. </li>
							<li class="fragment">Corpus: Our sample of units to analyse. </li>
							<li class="fragment">Features/tokens: The entity we use to quantify our texts (most often words.) </li>
						</ul>
					</section>
					<section>
						<h2>Bag of words (unigrams) </h2>
						<p class="fragment">We discard the word order in each text completely and only look at which words are used and how often in each text. </p>
						<p class="fragment">We also call this <em>tokenising</em>. </p>
						<p class="fragment">Improve unigrams by using bigrams, trigrams, or n-grams. </p>
						<p class="fragment">More advanced text analysis methods exist, but we will not cover that in this class. </p>
					</section>
					<section>
						<p>The result of this is a </p>
						<h2>Document-term matrix. </h2>
						<p>Also known as a document-feature-matrix</p>
						<p class="fragment">Additional preprossing: </p>
						<ul>
							<li class="fragment">Stemming (or more advanced lematisation) </li>
							<li class="fragment">Removing stop words, punctuation, and rare words. </li>
							<li class="fragment">Remove capitalisation. </li>
						</ul>
					</section>
					<section>
						<h3>document-term-matrix</h3>
						
					</section>
				</section>
				
				
				
				
				<section>
					<h3 style="color: rgb(0,101,189)">Analysing text data. </h3>
					<section>
						<table>
							<thead>
								<tr>
									<th></th>
									<th colspan="2" style="text-align: center;">Scale</th>
								</tr>
								<tr>
									<th></th>
									<th>Categorical</th>
									<th>Continuous (scaling)</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<th>Supervised </th>
									<td>Classification (known categories) </td>
									<td>Clustering (unkown categories) </td>
								</tr>
								<tr>
									<th>Unsupervised </th>
									<td>Scaling (known scale) </td>
									<td>Exploring dimensions (unknown scale) </td>
								</tr>
							</tbody>
						</table>
					</section>
					<section>
						<h3>Classifying documents into known categories </h3>
						<p class="fragment">Goal: Either categorise individual documents or assess overall distribution of documents in each category. </p>
						<ul>
							<li class="fragment">Dictionary methods </li>
							<li class="fragment">Supervised ML </li>
						</ul>
						<p class="fragment">Validation, relatively straight forward. </p>
					</section>
					<section>
						<h3>Discovering categories and topics </h3>
						<p>Clustering data - unsupervised methods </p>
						<ul>
							<li class="fragment">FAC (fully automated clustering) </li>
							<li class="fragment">CAC (computer assisted clustering) </li>
						</ul>
						<p class="fragment">Challenge to choose number of clusters. </p>
						<p class="fragment">And challenge to validate clusters: </p>
						<ul>
							<li class="fragment">Semantic validation </li>
							<li class="fragment">Predictive validation </li>
							<li class="fragment">Convergent validation </li>
						</ul>
					</section>
					<section>
						<h3>Scaling political actors </h3>
						<p>Continuous (nummeric) response variable. </p>
						<p class="fragment">Goal should be to score actors (or objects) on a political dimension that is useful to our analysis. </p>
						<p class="fragment">So the goal is <em>not</em> to prefectly model the text. </p>
						<ul>
							<li class="fragment">Supervised scaling: fx. Wordscores.  </li>
							<li class="fragment">Unsupervised scaling: fx. wordfish. </li>
						</ul>
						<p class="fragment">General challenge is an asssumption about ideological dominance.</p>
					</section>
				
				</section>
					
				<section>
					<h3 style="color: rgb(0,101,189)">Possibilities with computational text analysis </h3>
					<p class="fragment">Four principles of automated text analysis: </p>
					<ol>
						<li class="fragment">All quantitative models of language are wrong - but some are useful. </li>
						<li class="fragment">Quantitative models for text amplify resources and augment humans. </li>
						<li class="fragment">There is no globally best method for automated text analysis. </li>
						<li class="fragment">Validate, validate, validate! </li>
					</ol>
					<p class="fragment">Do you agree with these principles? </p>
				</section>
				
				
				
				

				<section>
					<h1>An example of a dictionay study in Political Science  </h1>
					<p class="fragment">Maerz, S. F. (2019). Simulating pluralism: The language of democracy in hegemonic authoritarianism. Political Research Exchange, 1(1)</p>
				</section>
				<section>
					<h3>Hypotheses</h3>
					<ol>
						<li class="fragment">The leaders of hegemonic regimes use a democratic style of language in their official speeches. </li>
						<li class="fragment">Closed regimes hardly refer to a democratic style of language in their official communication. </li>
						<li class="fragment">The leaders of competitive regimes use less democratic terms than those of hegemonic regimes. </li>
					</ol>
				</section>
				<section>
					<h3>Autocratic, hegemonic, and democratic regimes </h3>
					<section>
						<h1>Conceptualisation </h1>
						<p class="fragment">Closed autocracy - Hegemonic regimes - Competitive regimes - Democracy </p>
						<p class="fragment">In final analysis "backsliding democracies" are added. </p>
						<ul>
							<li class="fragment">Closed autocracies: No elected legislatures or single-party regime. </li>
							<li class="fragment">Hegemonic regimes: Hold elections, but does not allow "real electoral competition" (p.6) </li>
							<li class="fragment">Competitive regimes: Allow "...at least a minimum amoun of <em>real</em> competition in multiparty elections." (p. 6) </li>
						</ul>
					</section>
					<section>
						<h1>Operationalisation </h1>
						<p class="fragment">Two indicators from "Database of Political Institutions (DPI):</p>
						<ul class="fragment">
							<li>Legislative electoral competitiveness </li>
							<li>Executive electoral competitiveness </li>
						</ul>
						<p class="fragment">The DPI is constructed by the World Bank and thouroughly documented on <a href="https://datacatalog.worldbank.org/dataset/wps2283-database-political-institutions">their website</a>. </p>
					</section>
					<section>
						<h1>Operationalisation </h1>
						<table>
							<thead>
								<tr>
									<th class="fragment" data-fragment-index="1">Closed </th>
									<th class="fragment" data-fragment-index="2">Hegemonic </th>
									<th class="fragment" data-fragment-index="3">competitive </th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td class="fragment" data-fragment-index="1">Both indices have scores of ≤ 4: no legislature, unelected legislature, or only one elected candidate or party.</td>
									<td class="fragment" data-fragment-index="2">1. One or both scores of  > 4 and < 7: multiple parties allowed, but one gets all or 75 percent of available seats. </br>
2. Legislative index scores 7, executive < 7: satellite parties to simulate competition while regime has full control.</td>
									<td class="fragment" data-fragment-index="3">Executive index or both indices have scores of 7: competitive elections for executive, largest party got less than 75 percent of available seats in legislative elections.</td>
								</tr>
							</tbody>
						</table>
					</section>
					<section>
						<h3>Data sample </h3>
						<ul>
							<li>Website with officially translated English speeches. </li>
							<li>At least 10 translated speeches. </li>
							<li>Random selection of democratic states included for reference. </li>
						</ul>
					</section>
					<section>
						<h3>Data sample </h3>
						<img src="pic/lecture3/Maerz-table1.svg" />
					</section>
				</section>
				<section>
					<h3>Democratic/autocratic language</h3>
					<section>
						<h3>Conceptualisation </h3>
						<p class="fragment">Distinction between <em>procedural</em> and <em>ideological</em> orientations. </p>
						<img src="pic/lecture3/Maerz-figure1.svg" width="100%" class="fragment" />
					</section>
					<section>
						<h3>Operationalisation </h3>
						<p class="fragment">Styles of language calculated as word frequencies from dictionary. </p>
						<h1 class="fragment">Dictionary construction</h1>
						<ul>
							<li class="fragment">Partly based on previously used dictionaries. </li>
							<li class="fragment">But mainly from a "qualitative assessment of a stratified sample of speeches" + literature: </li>
							<ul>
								<li class="fragment">Most recent speech from each case sampled. </li>
								<li class="fragment">This sample used as "pool of keywords". </li>
								<li class="fragment">Keywords assigned to categories based on theory. </li>
							</ul>
						</ul>
						<p class="fragment">Good way to construct dictionary? Potential problems? </p>
					</section>
					<section>
						<h3>Operationalisation </h3>
						<h1 class="fragment">Validation of dictionary </h1>
						<ul>
							<li class="fragment">Qualitative check of codings in sample of 110 speeches. </li>
							<ul>
								<li class="fragment">Random sample of 5% of speeches from each case, excluding those already used to construct dictionary. </li>
								<li class="fragment">Keywords-in-context search. </li>
							</ul>
							<li class="fragment">Frequent negations and ambigiuous terms excluded. </li>
						</ul>
						<p class="fragment">Can you think of other ways to validate dictionary? </p>
						<p class="fragment"><a href="Dictionary+for+the+Analysis.html">Final dictionary available from link in paper. </a></p>
					</section>
				</section>
				<section>
					<h3>Findings</h3>
					<img src="pic/lecture3/Maerz-figure3.svg" width="75%"/>
				</section>
				
				
				
				<section>
					<h1>String manipulation in R</h1>
					
					<p class="fragment">Tomorrow's exercise will introduce the stringR package</p>
					<p class="fragment">Help us with very basic string manipulation. </p>
					<p class="fragment">Standardised functions for a lot of the procedures talked about today. </p>
					<h3 class="fragment">But...</h3>
					<p class="fragment">Good to know basics: </p>
					<ul>
							<li class="fragment">Better understanding of what is going on. </li>
							<li class="fragment">Enable you to do things exactly the way you want to. </li>
							<li class="fragment">It might be part of your exam. </li>
					</ul>
				</section>
				
				
			</div>
		</div>
		

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true }
				]
			});
		</script>
	</body>
</html>
